{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'dependent.csv', 'independent.csv', 'SubmissionFormat.csv', 'test.csv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('independent.csv',parse_dates=['date_recorded'], index_col='id')\n",
    "Y = pd.read_csv('dependent.csv', index_col='id').values.reshape(-1)\n",
    "#X_train = pd.read_csv('independent.csv',parse_dates=['date_recorded'], index_col='id', usecols=['id','date_recorded','amount_tsh','funder'], nrows=1000)\n",
    "#X_test = pd.read_csv('test.csv',parse_dates=['date_recorded'], index_col='id')\n",
    "X_test1 = pd.read_csv('test.csv',parse_dates=['date_recorded'], index_col='id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listo = list(X_train.select_dtypes(include=['object']).columns)\n",
    "listo1 = list(X_test.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listn = list(X_train.select_dtypes(include=['float64', 'int64']).columns)\n",
    "listn1 = list(X_test.select_dtypes(include=['float64', 'int64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lake Victoria              7745\n",
       "Pangani                    6758\n",
       "Rufiji                     5918\n",
       "Internal                   5796\n",
       "Lake Tanganyika            4813\n",
       "Wami / Ruvu                4511\n",
       "Lake Nyasa                 3746\n",
       "Ruvuma / Southern Coast    3404\n",
       "Lake Rukwa                 1859\n",
       "Name: basin, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['basin'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "numeric_pipe = Pipeline([\n",
    "            ('imputation',SimpleImputer(strategy='mean')),\n",
    "              ('scalar', StandardScaler())\n",
    "             \n",
    "            ])\n",
    "\n",
    "categorie_pipe = Pipeline([\n",
    "         ('imputation', SimpleImputer(strategy='most_frequent')),\n",
    "         ('ohe', OrdinalEncoder())\n",
    "        ])\n",
    "Tran_colon= ColumnTransformer(transformers=[('numeric', numeric_pipe, ['amount_tsh','latitude','longitude','gps_height','population','construction_year']),\n",
    "                                           ('cat', categorie_pipe, ['region','extraction_type','payment','water_quality','waterpoint_type',\n",
    "                                                                    'management', 'quantity','basin']),\n",
    "                                ],\n",
    "                             remainder='drop')\n",
    "\n",
    "#business_model = Pipeline([('Tran_colon',Tran_colon),\n",
    " #                 ('estimator', LogisticRegression(solver='lbfgs', multi_class='auto') )])\n",
    "\n",
    "\n",
    "#labelencoder.fit_transform(Y_train['status_group'])\n",
    "#business_model = Pipeline([('Tran_colon',Tran_colon),\n",
    " #                     ('estimator', RandomForestClassifier() )])\n",
    "#business_model = Pipeline([('Tran_colon',Tran_colon),\n",
    " #                       ('estimator', RandomForestClassifier() )])\n",
    "business_model = Pipeline([('Tran_colon',Tran_colon),\n",
    "                           ('estimator', GridSearchCV(RandomForestClassifier(), \n",
    "                            param_grid = {'max_depth': range(40,150,10),\n",
    "                                          'n_estimators': range(100, 200, 25)},\n",
    "                             cv=2, verbose=1\n",
    "                             ))\n",
    "                           \n",
    "                          ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 44 candidates, totalling 88 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed: 74.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('Tran_colon', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numeric', Pipeline(memory=None,\n",
       "     steps=[('imputation', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       ve...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046464646464646"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 140, 'n_estimators': 150}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_model.named_steps['estimator'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 39)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test1 = business_model.predict(X_test1)\n",
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non functional', 'functional', 'non functional', ...,\n",
       "       'functional', 'functional', 'non functional'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(Y_test1, index = X_test1.index, columns= ['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('hector.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
